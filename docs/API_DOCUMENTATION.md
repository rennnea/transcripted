
# TranscriptedAI Service API Documentation

## 1. Overview

The **TranscriptedAI Service Layer** (`services/geminiService.ts`) acts as the primary interface between the React frontend and the Google Gemini API. It handles file upload, transcription orchestration, data analysis, and context caching.

The service utilizes a **Progressive Two-Stage Pipeline** to optimize user experience:
1.  **Stage 1 (Synchronous):** Strict transcription (audio-to-text).
2.  **Stage 2 (Asynchronous):** Deep reasoning (Summarization, Sentiment, Entity Extraction, Grounding).

---

## 2. Authentication

The service requires a valid **Google Gemini API Key**.

- **Configuration:** The key is loaded via the environment variable `process.env.[[YOUR_API_KEY]]`.
- **Client Initialization:** The `@google/genai` client is initialized as a singleton within the service module.

```typescript
const ai = new GoogleGenAI({ apiKey: process.env.[[YOUR_API_KEY]];
```

> **Security Note:** In the current client-side architecture, the API key is embedded in the build. For production deployment, keys should be proxied through a backend or input by the user via a "Bring Your Own Key" (BYOK) interface.

---

## 3. Data Models (`types.ts`)

### 3.1 `TranscriptionOptions`
Configuration object passed to the pipeline to control model behavior.

| Property | Type | Description |
| :--- | :--- | :--- |
| `language` | `string` | BCP-47 language code (e.g., `'en-US'`, `'es-ES'`). |
| `enableDiarization` | `boolean` | If `true`, attempts to distinguish speakers (Speaker 1, Speaker 2). |
| `enableSummary` | `boolean` | If `true`, triggers the summarization step in Stage 2. |
| `summaryLength` | `string` | `'Short'`, `'Medium'`, or `'Long'`. |
| `summaryDetail` | `string` | `'Key Points'`, `'Detailed'`, or `'Comprehensive'`. |
| `summaryStructure` | `string` | `'Paragraph'`, `'Bullets'`, or `'Key-Value Pairs'`. |
| `enableEntityExtraction`| `boolean` | If `true`, extracts People, Organizations, and Locations. |
| `enableSentimentAnalysis`| `boolean` | If `true`, performs overall and trend sentiment analysis. |
| `enableSearchGrounding` | `boolean` | If `true`, uses Google Search tool to verify facts in the summary. |
| `autoSave` | `boolean` | If `true`, automatically commits the result to local IndexedDB history upon completion. |

### 3.2 `TranscriptionSegment`
Represents a single atomic unit of speech.

```typescript
interface TranscriptionSegment {
  timestamp: string; // Format: "HH:MM:SS"
  speaker: string;   // e.g., "Speaker 1"
  text: string;      // The transcribed spoken content
}
```

### 3.3 `AnalysisData` (Stage 2 Output)
Rich insights generated by the `gemini-3-pro-preview` model.

```typescript
interface AnalysisData {
  summary: string;
  sentiment: {
    overall: string; // e.g., "Positive", "Neutral"
    trend: Array<{ segment: number; sentiment: 'Positive'|'Negative'|'Neutral' }>;
  };
  entities: {
    [category: string]: string[]; // e.g., { "People": ["John Doe"] }
  };
  sources: Array<any>; // Grounding metadata from Google Search
}
```

---

## 4. Core Methods

### 4.1 `processAudioPipeline`

The main orchestrator function. It manages the upload and initiates both processing stages.

**Signature:**
```typescript
export const processAudioPipeline = async (
    file: File, 
    options: TranscriptionOptions
): Promise<PipelineResponse>
```

**Parameters:**
- `file`: The raw JavaScript `File` object from the input input.
- `options`: Configuration settings for the transcription.

**Returns:** `Promise<PipelineResponse>`
An object containing the immediate results and promises for background tasks.

```typescript
interface PipelineResponse {
  // Available immediately upon resolution of processAudioPipeline
  initialResult: RawTranscriptionData; 
  
  // Resolves later with deep insights
  analysisPromise: Promise<AnalysisData>; 
  
  // Resolves later with cache metadata
  cachePromise: Promise<{ name: string; ttl: number } | undefined>; 
}
```

#### Usage Example:

```typescript
import { processAudioPipeline } from './services/geminiService';

async function handleUpload(file: File) {
  // 1. Call the pipeline
  const { initialResult, analysisPromise } = await processAudioPipeline(file, options);
  
  // 2. Render Text Immediately (Stage 1)
  console.log("Transcription:", initialResult.transcription);
  
  // 3. Wait for Analysis (Stage 2)
  analysisPromise.then((analysis) => {
    console.log("Summary:", analysis.summary);
    console.log("Sentiment:", analysis.sentiment);
  });
}
```

---

## 5. Pipeline Architecture

### Step A: File Upload (Internal)
- **Method:** `ai.files.upload`
- **Purpose:** Uploads audio binary to Gemini storage to bypass HTTP payload limits (413 Errors) common with Base64.
- **Output:** Returns a `fileUri` reference.

### Step B: Strict Transcription (Stage 1)
- **Model:** `gemini-2.5-flash`
- **Configuration:** `responseMimeType: "application/json"`
- **Prompt:** Enforces a strict JSON schema for timestamps and speaker labels.
- **Priority:** High / Blocking.

### Step C: Deep Analysis (Stage 2)
- **Model:** `gemini-3-pro-preview`
- **Configuration:** Uses tools (`googleSearch`) if grounding is enabled, otherwise standard JSON generation.
- **Priority:** Low / Non-blocking background process.

### Step D: Context Caching
- **Method:** `ai.caches.create`
- **Purpose:** Caches the full transcript tokens on the Gemini server side.
- **Benefit:** Allows the Chatbot to query the document repeatedly without re-sending the full context tokens, saving cost and latency.
- **TTL:** Defaults to 1200 seconds (20 minutes).

---

## 6. Error Handling

The service layer throws standard JavaScript `Error` objects. Frontend components should wrap calls in `try/catch` blocks.

**Common Errors:**
- `[[YOUR API]] environment variable is not set`: Configuration error.
- `Failed to upload file`: Network connectivity issues or file type validation failure.
- `429 Too Many Requests`: Quota limits reached on the API key.
- `400 Bad Request`: Often caused by malformed audio or unsupported codecs.
